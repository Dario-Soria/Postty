import type { FastifyInstance, FastifyRequest, FastifyReply } from 'fastify';
import { GoogleGenerativeAI } from '@google/generative-ai';
import * as logger from '../utils/logger';

const GEMINI_MODEL = 'gemini-2.0-flash';

interface ChatRequest {
  userMessage: string;
  conversationHistory: string[];
  currentData: {
    // Block 1: Scene context
    sceneContext: string;        // Full scene description in one answer
    sceneConfirmed: boolean;     // User said "no more details"
    
    // Block 2: Template texts
    templateShown: boolean;      // We've shown the template
    text1: string;               // First text slot (e.g., product name)
    text2: string;               // Second text slot (e.g., brand)
    text3: string;               // Third text slot (e.g., promo)
    text4: string;               // Fourth text slot (e.g., extra)
    currentTextSlot: number;     // Which slot we're asking for (1-4)
    
    // Block 3: Format
    format: string;              // 1:1 or 9:16
    
    // Derived
    style: string;               // Extracted from context
  };
}

interface ChatResponse {
  nextQuestion: string;
  extractedData: Partial<ChatRequest['currentData']>;
  isReadyToGenerate: boolean;
  showTemplate?: boolean;        // Signal to frontend to show template image
}

export default async function geminiChatRoutes(fastify: FastifyInstance): Promise<void> {
  fastify.post('/gemini-chat', async (request: FastifyRequest, reply: FastifyReply) => {
    try {
      const body = request.body as ChatRequest;
      const { userMessage, conversationHistory, currentData } = body;

      const apiKey = process.env.GEMINI_API_KEY;
      if (!apiKey) {
        throw new Error('GEMINI_API_KEY not set');
      }

      const genAI = new GoogleGenerativeAI(apiKey);
      const model = genAI.getGenerativeModel({ model: GEMINI_MODEL });

      // Determine current phase based on data
      const phase = !currentData.sceneContext ? 'SCENE_ASK' :
                    !currentData.sceneConfirmed ? 'SCENE_CONFIRM' :
                    !currentData.templateShown ? 'SHOW_TEMPLATE' :
                    currentData.currentTextSlot <= 4 && !currentData.text4 ? 'ASK_TEXTS' :
                    !currentData.format ? 'ASK_FORMAT' : 'READY';

      const systemPrompt = `Sos un asistente de Postty que ayuda a crear im√°genes promocionales.
Tu trabajo es guiar al usuario paso a paso, de forma NATURAL y AMIGABLE.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ESTADO ACTUAL:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- Fase actual: ${phase}
- Contexto de escena: ${currentData.sceneContext || '(pendiente)'}
- Escena confirmada: ${currentData.sceneConfirmed ? 'S√ç' : 'NO'}
- Template mostrado: ${currentData.templateShown ? 'S√ç' : 'NO'}
- Texto 1: ${currentData.text1 || '(pendiente)'}
- Texto 2: ${currentData.text2 || '(pendiente)'}
- Texto 3: ${currentData.text3 || '(pendiente)'}
- Texto 4: ${currentData.text4 || '(pendiente)'}
- Slot actual: ${currentData.currentTextSlot || 1}
- Formato: ${currentData.format || '(pendiente)'}

HISTORIAL:
${conversationHistory.slice(-4).join('\n')}

MENSAJE DEL USUARIO: "${userMessage}"

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
FLUJO POR BLOQUES (seguir estrictamente):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìç BLOQUE 1: ESCENA (una sola pregunta abierta)
Si no tenemos sceneContext:
‚Üí Pregunta: "Contame todo sobre la imagen: ¬øqu√© estilo quer√©s? ¬øCon persona o solo producto? ¬øEn qu√© lugar o ambiente?"
‚Üí Extra√© TODO lo que diga el usuario en "sceneContext"
‚Üí Detect√° el estilo (old-money, elegante, minimalista, vibrante, urbano) y guardalo en "style"

Si tenemos sceneContext pero NO sceneConfirmed:
‚Üí Responde: "Perfecto, voy a crear [resumen de lo que dijo]. ¬øQuer√©s agregar alg√∫n detalle m√°s o as√≠ est√° bien?"
‚Üí Si dice "est√° bien", "no", "asi", "dale" ‚Üí sceneConfirmed = true
‚Üí Si agrega algo ‚Üí actualiz√° sceneContext

üìç BLOQUE 2: TEMPLATE (preguntar textos uno por uno)
Si sceneConfirmed pero NO templateShown:
‚Üí Responde: "Genial! Ahora vamos con los textos. Tengo un template con 4 espacios para texto."
‚Üí showTemplate = true, templateShown = true

Si templateShown y currentTextSlot = 1 y no tenemos text1:
‚Üí Pregunta: "üìù Texto 1 (arriba, el t√≠tulo del producto): ¬øqu√© ponemos?"
‚Üí Cuando responda ‚Üí text1 = respuesta, currentTextSlot = 2

Si currentTextSlot = 2 y no tenemos text2:
‚Üí Pregunta: "üìù Texto 2 (subt√≠tulo o marca): ¬øqu√© ponemos? (pod√©s decir 'nada' si no quer√©s)"
‚Üí Cuando responda ‚Üí text2 = respuesta (o ""), currentTextSlot = 3

Si currentTextSlot = 3 y no tenemos text3:
‚Üí Pregunta: "üìù Texto 3 (promoci√≥n grande, ej: 30% OFF): ¬øqu√© ponemos?"
‚Üí Cuando responda ‚Üí text3 = respuesta, currentTextSlot = 4

Si currentTextSlot = 4 y no tenemos text4:
‚Üí Pregunta: "üìù Texto 4 (extra abajo, ej: ENV√çO GRATIS): ¬øqu√© ponemos? (pod√©s decir 'nada')"
‚Üí Cuando responda ‚Üí text4 = respuesta (o ""), currentTextSlot = 5

üìç BLOQUE 3: FORMATO
Si tenemos todos los textos pero no format:
‚Üí Pregunta: "¬øPara feed (cuadrado) o stories (vertical)?"
‚Üí Cuando responda ‚Üí format = "1:1" o "9:16"

üìç BLOQUE 4: CONFIRMAR
Si tenemos TODO:
‚Üí Muestra resumen y pregunta "¬øGeneramos?"
‚Üí Si confirma ‚Üí isReadyToGenerate = true

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
RESPONDE SOLO JSON (sin markdown):
{
  "nextQuestion": "tu respuesta natural",
  "extractedData": {
    "sceneContext": "todo lo que dijo sobre la escena o null",
    "sceneConfirmed": true/false o null,
    "style": "old-money/elegante/minimalista/vibrante/urbano o null",
    "templateShown": true/false o null,
    "text1": "texto o null",
    "text2": "texto o null", 
    "text3": "texto o null",
    "text4": "texto o null",
    "currentTextSlot": numero 1-5 o null,
    "format": "1:1 o 9:16 o null"
  },
  "isReadyToGenerate": false,
  "showTemplate": false
}`;

      const result = await model.generateContent(systemPrompt);
      const response = result.response;
      const text = response.text();

      // Parse JSON from response
      let parsed: ChatResponse;
      try {
        // Remove markdown code blocks if present
        const cleanText = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
        // Find JSON in response
        const jsonStart = cleanText.indexOf('{');
        const jsonEnd = cleanText.lastIndexOf('}');
        const jsonStr = cleanText.slice(jsonStart, jsonEnd + 1);
        parsed = JSON.parse(jsonStr);
      } catch (e) {
        logger.warn('Failed to parse Gemini response, using fallback');
        parsed = {
          nextQuestion: "Contame: ¬øqu√© estilo quer√©s? ¬øCon persona o solo producto? ¬øEn qu√© ambiente?",
          extractedData: {},
          isReadyToGenerate: false,
        };
      }

      // Clean up extracted data (remove nulls and "null" strings)
      const cleanedData: Partial<ChatRequest['currentData']> = {};
      if (parsed.extractedData) {
        for (const [key, value] of Object.entries(parsed.extractedData)) {
          if (value !== null && value !== 'null' && value !== undefined) {
            // Handle boolean values
            if (typeof value === 'boolean') {
              (cleanedData as any)[key] = value;
            }
            // Handle numbers
            else if (typeof value === 'number') {
              (cleanedData as any)[key] = value;
            }
            // Handle non-empty strings
            else if (typeof value === 'string' && value.trim() !== '') {
              (cleanedData as any)[key] = value;
            }
          }
        }
      }

      logger.info(`üìù Chat phase, extracted: ${JSON.stringify(cleanedData)}`);

      return reply.send({
        nextQuestion: parsed.nextQuestion || "¬øQu√© m√°s te gustar√≠a ajustar?",
        extractedData: cleanedData,
        isReadyToGenerate: parsed.isReadyToGenerate || false,
        showTemplate: parsed.showTemplate || false,
      });

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : 'Unknown error';
      logger.error('Gemini chat error:', errorMsg);
      
      return reply.send({
        nextQuestion: "Perd√≥n, ¬øpod√©s repetirme eso?",
        extractedData: {},
        isReadyToGenerate: false,
      });
    }
  });

  logger.info('‚úÖ Gemini chat route registered: /gemini-chat');
}

